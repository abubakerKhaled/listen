# Technical Decisions

This document explains the rationale behind key architectural and technical decisions made during the development of Listen.

---

## üìã Decision Log

| ID | Decision | Status | Date |
|----|----------|--------|------|
| D1 | [Use faster-whisper over openai-whisper](#d1-faster-whisper-over-openai-whisper) | ‚úÖ Implemented | 2024 |
| D2 | [GTK4/libadwaita for GUI](#d2-gtk4libadwaita-for-gui) | ‚úÖ Implemented | 2024 |
| D3 | [AppImage for distribution](#d3-appimage-for-distribution) | ‚úÖ Implemented | 2024 |
| D4 | [Automatic model selection](#d4-automatic-model-selection) | ‚úÖ Implemented | 2024 |
| D5 | [Arabic-optimized transcription settings](#d5-arabic-optimized-transcription) | ‚úÖ Implemented | 2024 |
| D6 | [Dual interface (GUI + CLI)](#d6-dual-interface-gui--cli) | ‚úÖ Implemented | 2024 |
| D7 | [State machine for GUI button](#d7-state-machine-for-gui-button) | ‚úÖ Implemented | 2024 |

---

## D1: faster-whisper over openai-whisper

### Context

OpenAI's Whisper model is the industry standard for speech-to-text transcription. There are two main Python implementations:

1. **openai-whisper**: Official OpenAI implementation using PyTorch
2. **faster-whisper**: Community reimplementation using CTranslate2

### Decision

**Use faster-whisper** as the transcription backend.

### Rationale

```mermaid
graph LR
    subgraph "openai-whisper"
        A1[PyTorch Backend]
        A2[~4GB RAM for small]
        A3[Slower inference]
        A4[Official support]
    end
    
    subgraph "faster-whisper"
        B1[CTranslate2 Backend]
        B2[~1GB RAM for small]
        B3[4x faster inference]
        B4[Community maintained]
    end
    
    style B1 fill:#90EE90
    style B2 fill:#90EE90
    style B3 fill:#90EE90
```

| Criteria | openai-whisper | faster-whisper | Winner |
|----------|---------------|----------------|--------|
| Inference Speed | Baseline | 4x faster | faster-whisper |
| Memory Usage | High | ~4x lower | faster-whisper |
| Model Compatibility | Native | Full compatibility | Tie |
| Installation Size | ~2GB | ~500MB | faster-whisper |
| GPU Support | CUDA | CUDA + CPU fallback | faster-whisper |

### Consequences

- ‚úÖ Significantly faster transcription
- ‚úÖ Lower memory footprint
- ‚úÖ Smaller installation size
- ‚ö†Ô∏è Depends on CTranslate2 library
- ‚ö†Ô∏è Community-maintained (but very active)

---

## D2: GTK4/libadwaita for GUI

### Context

Multiple GUI frameworks are available for Python on Linux:

- **GTK4/libadwaita**: Native GNOME toolkit
- **Qt/PyQt5/PyQt6**: Cross-platform toolkit
- **Tkinter**: Python's built-in GUI
- **Web-based (Electron/Flask)**: Browser-based UI

### Decision

**Use GTK4 with libadwaita** for the graphical interface.

### Rationale

```mermaid
pie title Framework Considerations
    "Native Look & Feel" : 35
    "System Integration" : 25
    "Installation Size" : 20
    "Modern Features" : 20
```

| Criteria | GTK4/Adwaita | Qt | Tkinter | Electron |
|----------|-------------|-----|---------|----------|
| Native Linux Feel | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê | ‚≠ê |
| Modern Design | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê | ‚≠ê‚≠ê‚≠ê |
| Bundle Size | Small (shared libs) | Medium | Tiny | Huge |
| Dark Mode | Automatic | Manual | Limited | Manual |
| Accessibility | Excellent | Good | Limited | Variable |

### Consequences

- ‚úÖ Perfect integration with GNOME/GTK-based desktops
- ‚úÖ Automatic dark mode support
- ‚úÖ Shared libraries (not bundled in AppImage)
- ‚úÖ Modern, professional appearance
- ‚ö†Ô∏è Requires GTK4/libadwaita installed (most distros have it)
- ‚ö†Ô∏è Less ideal on KDE/Qt-based desktops (still works)

---

## D3: AppImage for Distribution

### Context

Linux has multiple packaging formats:

- **AppImage**: Universal, single-file format
- **Flatpak**: Sandboxed with runtime dependencies
- **Snap**: Canonical's sandboxed format
- **Native packages (.deb/.rpm)**: Distribution-specific

### Decision

**Use AppImage** as the primary distribution format.

### Rationale

```mermaid
graph TB
    subgraph "Distribution Requirements"
        R1[Single File Download]
        R2[No Root Required]
        R3[Works on Any Distro]
        R4[Self-Contained]
    end
    
    subgraph "AppImage Benefits"
        B1[‚úì One .AppImage file]
        B2[‚úì chmod +x and run]
        B3[‚úì Universal format]
        B4[‚úì Bundles Python + deps]
    end
    
    R1 --> B1
    R2 --> B2
    R3 --> B3
    R4 --> B4
```

| Format | Sandbox | Root Required | Size | Complexity |
|--------|---------|---------------|------|------------|
| AppImage | No | No | ~180MB | Low |
| Flatpak | Yes | No | ~300MB+ | Medium |
| Snap | Yes | No | ~400MB+ | Medium |
| .deb/.rpm | No | Yes | Variable | High |

### Consequences

- ‚úÖ Single file, easy to download and run
- ‚úÖ No installation required
- ‚úÖ Works on Ubuntu, Fedora, Arch, etc.
- ‚úÖ User can keep multiple versions
- ‚ö†Ô∏è Larger file size (~180MB due to bundled Python)
- ‚ö†Ô∏è GTK4/libadwaita must be system-installed

---

## D4: Automatic Model Selection

### Context

Whisper models range from "tiny" (39M parameters) to "large" (1.5B parameters). Users have varying hardware capabilities.

### Decision

**Automatically select the optimal model** based on detected hardware.

### Rationale

```mermaid
flowchart TD
    A[App Start] --> B{CUDA Available?}
    B -->|No| C[tiny model<br/>CPU inference]
    B -->|Yes| D[Query VRAM]
    D --> E{VRAM ‚â• 4GB?}
    E -->|Yes| F[medium model<br/>Best Arabic accuracy]
    E -->|No| G{VRAM ‚â• 2GB?}
    G -->|Yes| H[small model<br/>Good balance]
    G -->|No| I[base model<br/>Low VRAM]
    
    style F fill:#90EE90
    style H fill:#FFEB3B
    style I fill:#FFB74D
    style C fill:#FFB74D
```

<p align="center">
  <img src="./images/model_selection.png" alt="Model Selection Flowchart" width="500">
</p>

**Model Selection Matrix**:

| Device | VRAM | Selected Model | Rationale |
|--------|------|----------------|-----------|
| CUDA | ‚â•4GB | `medium` | Best accuracy for Arabic/multilingual |
| CUDA | ‚â•2GB | `small` | Good balance of speed and accuracy |
| CUDA | <2GB | `base` | Fit within limited VRAM |
| CPU | ‚Äî | `tiny` | Fastest CPU inference |

### Consequences

- ‚úÖ Optimal experience out of the box
- ‚úÖ Users don't need to understand model sizes
- ‚úÖ Prevents OOM errors on low-VRAM GPUs
- ‚úÖ Falls back gracefully to CPU
- ‚ö†Ô∏è Users with specific needs can still override with `--model`

---

## D5: Arabic-Optimized Transcription

### Context

Whisper's default settings work well for English but can produce hallucinations or errors with Arabic and other complex scripts.

### Decision

**Tune transcription parameters for Arabic and RTL languages**.

### Implementation

```python
segments, info = self._model.transcribe(
    audio_source,
    beam_size=8,                        # Up from 5
    patience=1.5,                       # Up from 1.0
    condition_on_previous_text=False,   # Prevents hallucination
    vad_filter=True,                    # Filter silence
)
```

### Rationale

| Parameter | Default | Optimized | Why |
|-----------|---------|-----------|-----|
| `beam_size` | 5 | 8 | Arabic has complex morphology; wider search helps |
| `patience` | 1.0 | 1.5 | More thorough search for script variations |
| `condition_on_previous_text` | True | **False** | Prevents Arabic hallucination (repetition loops) |
| `vad_filter` | False | **True** | Reduces false transcriptions from silence |

### Consequences

- ‚úÖ Significantly improved Arabic transcription quality
- ‚úÖ Reduced hallucination/repetition issues
- ‚úÖ Works well for all languages (not just Arabic)
- ‚ö†Ô∏è Slightly slower inference due to larger beam size
- ‚ö†Ô∏è May skip some context with `condition_on_previous_text=False`

---

## D6: Dual Interface (GUI + CLI)

### Context

Users have different preferences and use cases:

- Some prefer graphical interfaces for ease of use
- Power users and automation require CLI access
- Some desktop environments work better with CLI

### Decision

**Provide both GUI and CLI interfaces** with the same core functionality.

### Architecture

```mermaid
graph TB
    subgraph "Entry Point"
        main["cli.py::main()"]
    end
    
    subgraph "Routing"
        check{--cli flag?}
    end
    
    subgraph "Interfaces"
        cli["ListenApp<br/>(Terminal UI)"]
        gui["ListenGUI<br/>(GTK4 Window)"]
    end
    
    subgraph "Shared Core"
        rec["AudioRecorder"]
        trans["Transcriber"]
    end
    
    main --> check
    check -->|Yes| cli
    check -->|No| gui
    cli --> rec
    cli --> trans
    gui --> rec
    gui --> trans
```

### Consequences

- ‚úÖ GUI for general users
- ‚úÖ CLI for terminal enthusiasts and automation
- ‚úÖ Shared core logic (no duplication)
- ‚úÖ Same features available in both modes
- ‚ö†Ô∏è CLI-specific features (push-to-talk) require `pynput`
- ‚ö†Ô∏è GUI requires GTK4/libadwaita

---

## D7: State Machine for GUI Button

### Context

The GUI has a single main action button that handles multiple functions: record, transcribe, and copy.

### Decision

**Implement a state machine** for the button behavior.

### State Diagram

```mermaid
stateDiagram-v2
    [*] --> Ready
    
    Ready --> Recording: Click
    Recording --> Transcribing: Click
    Transcribing --> Result: Complete
    Result --> Ready: Click
    
    note right of Ready
        Button: "üé§ Record"
        Style: suggested-action
    end note
    
    note right of Recording
        Button: "‚èπÔ∏è Transcribe"
        Style: destructive-action
    end note
    
    note right of Transcribing
        Button: "‚è≥ Transcribing..."
        State: disabled
    end note
    
    note right of Result
        Button: "üìã Copy & New"
        Style: suggested-action
    end note
```

<p align="center">
  <img src="./images/state_machine.png" alt="GUI State Machine" width="500">
</p>

### Rationale

| Approach | Pros | Cons |
|----------|------|------|
| Multiple buttons | Clear actions | Cluttered UI |
| Modal dialogs | Separation | Disruptive |
| **Single stateful button** | Clean UI, guided flow | Requires state management |

### Consequences

- ‚úÖ Clean, minimal UI with single main action
- ‚úÖ Guided user flow (can't skip steps)
- ‚úÖ Clear visual feedback (colors, labels change)
- ‚úÖ Easy to understand workflow
- ‚ö†Ô∏è Slightly more complex code (state management)

---

## üìö Future Considerations

### Potential Future Decisions

| Topic | Options | Status |
|-------|---------|--------|
| Multi-language UI | gettext, hardcoded | Not started |
| Hotword detection | Always-on mic, wake word | Not started |
| Speaker diarization | Pyannote, whisperx | Not started |
| Cloud sync | Dropbox, Google Drive | Not planned |

---

<p align="center">
  <a href="./modules.md">‚Üê Core Modules</a> |
  <a href="./README.md">Index</a> |
  <a href="./api-reference.md">API Reference ‚Üí</a>
</p>
